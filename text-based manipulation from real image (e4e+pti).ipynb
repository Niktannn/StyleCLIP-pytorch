{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e1dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL.Image\n",
    "import os\n",
    "from embedding import get_delta_t\n",
    "from manipulator import Manipulator\n",
    "from mapper import get_delta_s\n",
    "from wrapper import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2')\n",
    "ckpt = 'pivot_tuning_inversion/checkpoints/model_PLPLIHFZUBII_multi_id.pt'\n",
    "G = Generator(ckpt, device)\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "fs3 = np.load('tensor/fs3.npy')\n",
    "expdir = 'pivot_tuning_inversion/test2'\n",
    "num_images = 1\n",
    "lst_alpha = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf855a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulator = Manipulator(G, device, lst_alpha, num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = [imgpath.split('.')[0] for imgpath in os.listdir('pivot_tuning_inversion/aligned2')]\n",
    "embedding_dir = 'pivot_tuning_inversion/embeddings/test/e4e/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = list()\n",
    "for image_name in image_names:\n",
    "    w = torch.load(embedding_dir+f'{image_name}/0.pt')\n",
    "    ws.append(w)\n",
    "ws = torch.cat(ws).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manipulator.set_real_img_projection(expdir, mode='w')\n",
    "manipulator.latent = ws\n",
    "manipulator.num_images = ws.shape[0]\n",
    "manipulator.styles = G.mapping_stylespace(ws)\n",
    "#manipulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07276238",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_alpha = [-3, 0]\n",
    "manipulator.set_alpha(lst_alpha)\n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "#classnames=['neutral face', 'face with smile']\n",
    "classnames=['face with eyes', 'face with big eyes']\n",
    "beta_threshold = 0.20\n",
    "delta_t = get_delta_t(classnames, model)\n",
    "delta_s, num_channel = get_delta_s(fs3, delta_t, manipulator, beta_threshold=beta_threshold)\n",
    "print(f'{num_channel} channels will be manipulated under the beta threshold {beta_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = manipulator.manipulate(delta_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1df150",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = manipulator.synthesis_from_styles(styles, 0, manipulator.num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f12569",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for imgs in all_imgs:\n",
    "    lst.append((imgs.permute(0,2,3,1)*127.5+128).clamp(0,255).to(torch.uint8).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306bd71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "H,W = (256,256)\n",
    "gw, gh = (manipulator.num_images, 1)\n",
    "\n",
    "for i, alpha in enumerate(lst_alpha):\n",
    "    print(alpha)\n",
    "    imgs = lst[i]\n",
    "    imgs_ = []    \n",
    "    for img in imgs:\n",
    "        imgs_.append( np.asarray( PIL.Image.fromarray(img, 'RGB').resize((H,W),PIL.Image.LANCZOS)))\n",
    "    imgs_ = np.stack(imgs_)\n",
    "    imgs_ = imgs_.reshape(gh,gw,H,W,3)\n",
    "    imgs_ = imgs_.transpose(0,2,1,3,4)\n",
    "    imgs_ = imgs_.reshape(gh*H, gw*W, 3)\n",
    "    display(PIL.Image.fromarray(imgs_, 'RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc6383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
